{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 前向传播\n",
    "\n",
    "前向传播（forward propagation或forward pass） 指的是：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b2f6340f383bbd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 前向传播计算图\n",
    "\n",
    "绘制计算图有助于我们可视化计算中操作符和变量的依赖关系。[图4.7.1](http://zh.d2l.ai/chapter_multilayer-perceptrons/backprop.html#fig-forward) 是与上述简单网络相对应的计算图， 其中正方形表示变量，圆圈表示操作符。 左下角表示输入，右上角表示输出。 注意显示数据流的箭头方向主要是向右和向上的。\n",
    "\n",
    "![图4.7.1](./img/forward.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecb980d69e4946fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 反向传播\n",
    "\n",
    "反向传播（backward propagation或backpropagation）指的是计算神经网络参数梯度的方法。 简言之，该方法根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。 该算法存储了计算某些参数梯度时所需的任何中间变量（偏导数）。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad34a65a3c554168"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练神经网络\n",
    "\n",
    "在训练神经网络时，前向传播和反向传播相互依赖。 对于前向传播，我们沿着依赖的方向遍历计算图并计算其路径上的所有变量。 然后将这些用于反向传播，其中计算顺序与计算图的相反。\n",
    "\n",
    "在训练神经网络时，在初始化模型参数后， 我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。 注意，反向传播重复利用前向传播中存储的中间值，以避免重复计算。 带来的影响之一是我们需要保留中间值，直到反向传播完成。 这也是训练比单纯的预测需要更多的内存（显存）的原因之一。 此外，这些中间值的大小与网络层的数量和批量的大小大致成正比。 因此，使用更大的批量来训练更深层次的网络更容易导致内存不足（out of memory）错误。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea0b05ef5a34217"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 小结\n",
    "\n",
    "- 前向传播在神经网络定义的计算图中按顺序计算和存储中间变量，它的顺序是从输入层到输出层。\n",
    "- 反向传播按相反的顺序（从输出层到输入层）计算和存储神经网络的中间变量和参数的梯度。\n",
    "- 在训练深度学习模型时，前向传播和反向传播是相互依赖的。\n",
    "- 训练比预测需要更多的内存。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8edeb351e44aa45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 练习\n",
    "\n",
    "1. 假设一些标量函数X的输入X是n x m矩阵。f相对于X的梯度维数是多少？\n",
    "2. 向本节中描述的模型的隐藏层添加偏置项（不需要在正则化项中包含偏置项）。\n",
    "    1. 画出相应的计算图。\n",
    "    2. 推导正向和反向传播方程。\n",
    "3. 计算本节所描述的模型，用于训练和预测的内存占用。\n",
    "4. 假设想计算二阶导数。计算图发生了什么？预计计算需要多长时间？\n",
    "5. 假设计算图对当前拥有的GPU来说太大了。\n",
    "    1. 请试着把它划分到多个GPU上。\n",
    "    2. 与小批量训练相比，有哪些优点和缺点？"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2024f23ee7ffbf58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
